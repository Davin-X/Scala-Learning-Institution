{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸŒ Distributed Systems Patterns\n",
    "\n",
    "**Phase 3: System Design - Scalable Distributed Architecture**\n",
    "\n",
    "**Master CAP theorem, consistency models, partitioning, and distributed fault tolerance**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Distributed Systems Fundamentals\n",
    "println(\"ğŸŒ DISTRIBUTED SYSTEMS - SCALABILITY & CONSISTENCY MASTERCLASS\")\n",
    "println()\n",
    "\n",
    "println(\"ğŸ”¥ The Eight Fallacies of Distributed Computing:\")\n",
    "println(\"1. âŒ The network is reliable\")\n",
    "println(\"2. âŒ Latency is zero\")\n",
    "println(\"3. âŒ Bandwidth is infinite\")\n",
    "println(\"4. âŒ The network is secure\")\n",
    "println(\"5. âŒ Topology doesn't change\")\n",
    "println(\"6. âŒ There is one administrator\")\n",
    "println(\"7. âŒ Transport cost is zero\")\n",
    "println(\"8. âŒ The network is homogeneous\")\n",
    "println()\n",
    "\n",
    "println(\"ğŸ¯ CAP Theorem Trade-offs:\")\n",
    "println(\"â€¢ Consistency: All nodes see same data simultaneously\")\n",
    "println(\"â€¢ Availability: Every request receives a response\")\n",
    "println(\"â€¢ Partition Tolerance: System works despite network splits\")\n",
    "println(\"â€¢ Choose 2 out of 3 in the face of network partitions\")\n",
    "println()\n",
    "\n",
    "println(\"âš¡ PACELC Theorem (extension):\")\n",
    "println(\"â€¢ If Partition (P), choose Availability (A) or Consistency (C)\")\n",
    "println(\"â€¢ Else when Latency (L), choose between low Latency (L) or high Consistency (C)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Consistency Models\n",
    "\n",
    "**Serializability vs. Eventual Consistency vs. Strong Consistency - choosing the right model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Consistency Models Implementation\n",
    "sealed trait ConsistencyLevel\n",
    "case object StrongConsistency extends ConsistencyLevel      // Linearizability/Serializability\n",
    "case object EventualConsistency extends ConsistencyLevel   // BASE properties\n",
    "case object ReadYourWrites extends ConsistencyLevel         // Session consistency\n",
    "case object MonotonicReads extends ConsistencyLevel         // No time travel\n",
    "case object CausalConsistency extends ConsistencyLevel     // Causally related writes\n",
    "case object BoundedStaleness extends ConsistencyLevel      // Maximum staleness guarantee\n",
    "\n",
    "case class ConsistencyRequirements(\n",
    "  system: String,\n",
    "  readLoad: Double,\n",
    "  writeLoad: Double,\n",
    "  acceptableLatency: Long,\n",
    "  consistencyNeeded: ConsistencyLevel,\n",
    "  availabilityTarget: Double\n",
    ")\n",
    "\n",
    "object ConsistencyAdvisor {\n",
    "  \n",
    "  def recommendCoherenceProtocol(reqs: ConsistencyRequirements): String = {\n",
    "    val loadRatio = reqs.readLoad / math.max(reqs.writeLoad, 1)\n",
    "    val highReadLowWrite = loadRatio > 10\n",
    "    val strictConsistency = reqs.consistencyNeeded == StrongConsistency\n",
    "    \n",
    "    // Recommendation logic\n",
    "    (reqs, loadRatio, strictConsistency) match {\n",
    "      case (reqs, lr, true) if lr > 100 => \n",
    "        \"Quorum-based consensus (Paxos/Raft) with read-modify-write cycles\"\n",
    "      case (reqs, lr, true) if lr > 10 => \n",
    "        \"Two-phase commit or synchronous replication\"\n",
    "      case (reqs, lr, true) => \n",
    "        \"Leader-based replication with WAL persistence\"\n",
    "      case (reqs, lr, false) if reqs.acceptableLatency < 50 => \n",
    "        \"Eventual consistency with anti-entropy (Amazon Dynamo-style)\"\n",
    "      case (reqs, lr, false) if reqs.acceptableLatency < 200 => \n",
    "        \"Cassandra-style tunable consistency levels\"\n",
    "      case _ => \"Multi-region active-active with CRDTs\"\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  def tradeOffAnalysis(reqs: ConsistencyRequirements): Map[String, String] = Map(\n",
    "    \"performance\" -> {\n",
    "      reqs.consistencyNeeded match {\n",
    "        case StrongConsistency => \"Slower due to coordination overhead\"\n",
    "        case EventualConsistency => \"Fast reads, coordination on conflicts\"\n",
    "        case _ => \"Balanced with tunable trade-offs\"\n",
    "      }\n",
    "    },\n",
    "    \"fault_tolerance\" -> {\n",
    "      reqs.availabilityTarget match {\n",
    "        case x if x >= 0.9999 => \"High replication, consistency relaxations\"\n",
    "        case x if x >= 0.99 => \"Multi-region, quorum-based decisions\"\n",
    "        case _ => \"Synchronous replication, stricter consistency\"\n",
    "      }\n",
    "    },\n",
    "    \"complexity\" -> {\n",
    "      if (reqs.consistencyNeeded == StrongConsistency) \"High - distributed locks, coordination\"\n",
    "      else if (reqs.consistencyNeeded == EventualConsistency) \"Medium - conflict resolution strategies\"\n",
    "      else \"High - custom consistency protocols\"\n",
    "    }\n",
    "  )\n",
    "}\n",
    "\n",
    "println(\"ğŸ“Š CONSISTENCY MODEL ANALYSIS IMPLEMENTED\")\n",
    "println(\"â€¢ Strong Consistency: Sequential operations, coordination overhead\")\n",
    "println(\"â€¢ Eventual Consistency: Conflicts require resolution, higher throughput\")\n",
    "println(\"â€¢ Read-Your-Writes: Session guarantees, UI-friendly\")\n",
    "println(\"â€¢ Causal Consistency: Partial ordering, dependency tracking\")\n",
    "println(\"â€¢ Choosing right model: Application requirements drive selection\")\n",
    "println()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—‚ï¸ Data Partitioning Strategies\n",
    "\n",
    "**Horizontal partitioning, sharding, and data distribution patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Data Partitioning Strategies\n",
    "sealed trait PartitioningStrategy\n",
    "case object HashPartitioning extends PartitioningStrategy        // Even distribution, range queries hard\n",
    "case object RangePartitioning extends PartitioningStrategy       // Range queries easy, uneven distribution\n",
    "case object AdaptivePartitioning extends PartitioningStrategy    // Hybrid approach\n",
    "case object DirectoryPartitioning extends PartitioningStrategy   // Lookup table, high lookup overhead\n",
    "case object EntityPartitioning extends PartitioningStrategy      // Domain-driven partitioning\n",
    "\n",
    "case class PartitionInfo(\n",
    "  node: String,\n",
    "  minKey: String,\n",
    "  maxKey: String,\n",
    "  recordCount: Long,\n",
    "  sizeInMB: Double\n",
    ")\n",
    "\n",
    "class PartitionManager {\n",
    "  \n",
    "  private val partitions = scala.collection.mutable.Map[String, PartitionInfo]()\n",
    "  \n",
    "  // Hash-based partitioning\n",
    "  def hashPartition(key: String, numPartitions: Int): Int = {\n",
    "    val hash = key.hashCode.abs\n",
    "    hash % numPartitions\n",
    "  }\n",
    "  \n",
    "  // Range-based partitioning (for sorted keys)\n",
    "  def rangePartition(key: String, ranges: Map[Int, (String, String)]): Option[Int] = {\n",
    "    ranges.collectFirst {\n",
    "      case (partition, (min, max)) if key >= min && key <= max => partition\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // Consistency routing\n",
    "  def findPartition(key: String, strategy: PartitioningStrategy): String = {\n",
    "    strategy match {\n",
    "      case HashPartitioning => \n",
    "        val partitionId = hashPartition(key, partitions.size)\n",
    "        s\"node_$partitionId\"\n",
    "      case RangePartitioning =>\n",
    "        // Find partition containing key\n",
    "        partitions.find(_._2.minKey <= key && _._2.maxKey >= key)\n",
    "          .map(_._1).getOrElse(\"unknown\")\n",
    "      case _ => \"adaptive\" // Simplified for demo\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // Rebalancing when adding/removing nodes\n",
    "  def rebalancePartitions(clusterSize: Int): Map[String, (Long, Long)] = {\n",
    "    // Calculate key ranges per partition\n",
    "    val totalKeys = math.pow(2, 32).toLong // Assume 32-bit keys\n",
    "    val keysPerNode = totalKeys / clusterSize\n",
    "    \n",
    "    (0 until clusterSize).map { nodeId =>\n",
    "      val startKey = nodeId * keysPerNode\n",
    "      val endKey = if (nodeId == clusterSize - 1) totalKeys - 1 else (nodeId + 1) * keysPerNode - 1\n",
    "      s\"node_$nodeId\" -> (startKey, endKey)\n",
    "    }.toMap\n",
    "  }\n",
    "\n",
    "  def getPartitionMetrics(): Map[String, PartitionInfo] = partitions.toMap\n",
    "  def addPartition(node: String, info: PartitionInfo): Unit = partitions.put(node, info)\n",
    "}\n",
    "\n",
    "println(\"ğŸ—‚ï¸ DATA PARTITIONING STRATEGIES IMPLEMENTED\")\n",
    "println(\"â€¢ Hash Partitioning: Even load, range queries require scatter-gather\")\n",
    "println(\"â€¢ Range Partitioning: Range queries fast, hotspots possible\")\n",
    "println(\"â€¢ Adaptive Partitioning: Hybrid strategies for changing workloads\")\n",
    "println(\"â€¢ Entity Partitioning: Domain boundaries, reduces cross-entity queries\")\n",
    "println()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Consensus & Coordination\n",
    "\n",
    "**Leader election, distributed locks, and agreement protocols**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Consensus Protocols Implementation\n",
    "sealed trait ConsensusProtocol\n",
    "case object Paxos extends ConsensusProtocol          // Distributed consensus\n",
    "case object Raft extends ConsensusProtocol           // Leader election + replication\n",
    "case object ViewStampedReplication extends ConsensusProtocol\n",
    "case object ZAB extends ConsensusProtocol           // ZooKeeper's protocol\n",
    "\n",
    "sealed trait ConsensusState\n",
    "case class Leader(term: Long, nodeId: String) extends ConsensusState\n",
    "case class Follower(term: Long, leaderId: String) extends ConsensusState\n",
    "case class Candidate(term: Long, votes: Set[String]) extends ConsensusState\n",
    "\n",
    "case class ConsensusMessage(\n",
    "  msgType: String,      // \"RequestVote\", \"AppendEntries\", etc.\n",
    "  term: Long,\n",
    "  sender: String,\n",
    "  payload: Map[String, Any],\n",
    "  timestamp: java.time.Instant = java.time.Instant.now()\n",
    ")\n",
    "\n",
    "class SimplifiedRaft {\n",
    "  private var state: ConsensusState = Follower(0L, \"\")\n",
    "  private val log = scala.collection.mutable.ArrayBuffer[(Long, Any)]()\n",
    "  private val peers = Set(\"node_1\", \"node_2\", \"node_3\")\n",
    "  \n",
    "  // Election timeout (simplified)\n",
    "  def startElection(): ConsensusState = {\n",
    "    val currentTerm = state match {\n",
    "      case Follower(term, _) => term + 1\n",
    "      case Candidate(term, _) => term + 1\n",
    "      case Leader(term, _) => term\n",
    "    }\n",
    "    \n",
    "    state = Candidate(currentTerm, Set.empty)\n",
    "    val votesReceived = peers.take(scala.util.Random.nextInt(peers.size)) // Random vote success\n",
    "    \n",
    "    if (votesReceived.size >= (peers.size + 1) / 2) { // Majority vote\n",
    "      state = Leader(currentTerm, \"self\")\n",
    "      println(s\"ğŸ¯ Elected leader for term $currentTerm\")\n",
    "    } else {\n",
    "      println(s\"âŒ Election failed for term $currentTerm\")\n",
    "      state = Follower(currentTerm, \"\")\n",
    "    }\n",
    "    state\n",
    "  }\n",
    "  \n",
    "  // Heartbeat/AppendEntries (simplified)\n",
    "  def sendHeartbeat(leaderTerm: Long): Unit = {\n",
    "    peers.foreach { peer =>\n",
    "      val message = ConsensusMessage(\n",
    "        \"AppendEntries\",\n",
    "        leaderTerm,\n",
    "        \"self\",\n",
    "        Map(\"leaderCommit\" -> log.size, \"entries\" -> List.empty[Any])\n",
    "      )\n",
    "      println(s\"ğŸ’“ Heartbeat to $peer in term $leaderTerm\")\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  def appendEntries(term: Long, entries: List[(Long, Any)]): Either[String, Unit] = {\n",
    "    val currentTerm = state match {\n",
    "      case Leader(t, _) if t == term || t < term => t\n",
    "      case Follower(t, _) if t <= term => term\n",
    "      case _ => 0L\n",
    "    }\n",
    "    \n",
    "    log.appendAll(entries)\n",
    "    Right(())  // In reality, would check sequence numbers\n",
    "  }\n",
    "  \n",
    "  def getLog() = log.toList\n",
    "  def getState() = state\n",
    "}\n",
    "\n",
    "println(\"ğŸ”„ CONSENSUS & COORDINATION IMPLEMENTED\")\n",
    "println(\"â€¢ Leader election: Majority voting, term advancement\")\n",
    "println(\"â€¢ Log replication: Append-only logs with consistency checks\")\n",
    "println(\"â€¢ Heartbeat monitoring: Leader failure detection\")\n",
    "println(\"â€¢ Term management: Election cycles and conflict resolution\")\n",
    "println()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Distributed System Architectures\n",
    "\n",
    "**Lambda/Kappa architectures, mastering batch vs stream processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Lambda Architecture Implementation\n",
    "sealed trait DataLayer\n",
    "case object BatchLayer extends DataLayer         // Hadoop, compute views on all data\n",
    "case object SpeedLayer extends DataLayer         // Streaming, approximate results\n",
    "case object ServingLayer extends DataLayer       // Pre-computed views, low-latency access\n",
    "\n",
    "// Kappa Architecture (streaming-first)\n",
    "sealed trait KappaComponent\n",
    "case object StreamProcessor extends KappaComponent\n",
    "case object StateStore extends KappaComponent\n",
    "case object SlowLayer extends KappaComponent     // Reprocessing stream from beginning\n",
    "\n",
    "case class DataPipeline(\n",
    "  architecture: String,  // \"lambda\" or \"kappa\"\n",
    "  batchLayer: Option[DataLayer],\n",
    "  speedLayer: Option[DataLayer],\n",
    "  servingLayer: DataLayer,\n",
    "  streamProcessor: Option[KappaComponent]\n",
    ")\n",
    "\n",
    "object ArchitectureComparison {\n",
    "  \n",
    "  val lambdaArchitecture = DataPipeline(\n",
    "    \"lambda\",\n",
    "    Some(BatchLayer),\n",
    "    Some(SpeedLayer),\n",
    "    ServingLayer,\n",
    "    None\n",
    "  )\n",
    "  \n",
    "  val kappaArchitecture = DataPipeline(\n",
    "    \"kappa\",\n",
    "    None,\n",
    "    None,\n",
    "    ServingLayer,\n",
    "    Some(StreamProcessor)\n",
    "  )\n",
    "  \n",
    "  def compareArchitectures(): Map[String, String] = {\n",
    "    Map(\n",
    "      \"complexity\" -> \"Lambda: Two code paths, higher complexity. Kappa: Single stream processing pipeline\",\n",
    "      \"consistency\" -> \"Lambda: Eventual consistency between layers. Kappa: Eventually consistent single system\",\n",
    "      \"real_time\" -> \"Lambda: Faster, two-tier processing. Kappa: Single pipeline, potentially slower\",\n",
    "      \"reprocessing\" -> \"Lambda: Reprocess batch data. Kappa: Reset stream from beginning\",\n",
    "      \"development\" -> \"Lambda: Maintain batch + streaming code. Kappa: Unified stream processing\",\n",
    "      \"scalability\" -> \"Both scale, Kappa often simpler for stream-first use cases\",\n",
    "      \"use_case\" -> \"Lambda: When batch quality > speed. Kappa: When speed = quality priority\"\n",
    "    )\n",
    "  }\n",
    "  \n",
    "  def chooseArchitecture(requirements: Map[String, Any]): String = {\n",
    "    val latencyCritical = requirements.get(\"latency_ms\").map(_.asInstanceOf[Long] < 100).getOrElse(false)\n",
    "    val reprocessingFreq = requirements.get(\"reprocess_frequency\").map(_.asInstanceOf[String]).getOrElse(\"rare\")\n",
    "    val teamSize = requirements.get(\"team_size\").map(_.asInstanceOf[Int]).getOrElse(10)\n",
    "    \n",
    "    (latencyCritical, reprocessingFreq, teamSize) match {\n",
    "      case (true, freq, size) if size > 5 => \"kappa\"  // Stream-first, team can handle complexity\n",
    "      case (false, \"frequent\", _) => \"lambda\"         // Batch reprocessing, different latency needs\n",
    "      case (false, \"rare\", size) if size <= 5 => \"kappa\" // Simpler pipeline for smaller team\n",
    "      case _ => \"lambda\"                            // Default to battle-tested lambda\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  def getAdvantages(arch: String): List[String] = {\n",
    "    arch.toLowerCase match {\n",
    "      case \"lambda\" => List(\n",
    "        \"Battle-tested architecture\",\n",
    "        \"Separates accuracy and speed concerns\",\n",
    "        \"Batch layer handles data corrections\",\n",
    "        \"Speed layer serves low-latency needs\",\n",
    "        \"Well-established patterns (Rolling, Pinball, etc.)\"\n",
    "      )\n",
    "      case \"kappa\" => List(\n",
    "        \"Single pipeline - simpler operations\",\n",
    "        \"Unified stream processing code\",\n",
    "        \"Better real-time capabilities\",\n",
    "        \"No serving layer consistency issues\",\n",
    "        \"Easier testing with deterministic reprocessing\"\n",
    "      )\n",
    "      case _ => List(\"Unknown architecture\")\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "println(\"ğŸ—ï¸ DISTRIBUTED SYSTEM ARCHITECTURES: LAMBDA vs KAPPA\")\n",
    "println()\n",
    "println(\"ğŸ”¥ Key Decision Factors:\")\n",
    "println(\"âœ“ Team expertise and size\")\n",
    "println(\"âœ“ Data reprocessing frequency\")\n",
    "println(\"âœ“ Latency requirements\")\n",
    "println(\"âœ“ Operational complexity tolerance\")\n",
    "println(\"âœ“ Historical data correction importance\")\n",
    "println()\n",
    "\n",
    "println(\"ğŸ’¡ Architecture Evolution:\")\n",
    "println(\"2010s: Lambda (batch + stream)\")\n",
    "println(\"2020s: Kappa (stream-first, faster processing)\")\n",
    "println(\"Future: Zeta (AI-powered, self-optimizing)\")\n",
    "println()\n",
    "\n",
    "println(\"ğŸ¯ Choose based on your specific use case, not trends!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
