{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Monitoring & Observability\n",
    "\n",
    "**Phase 3: System Design - Production Operations**\n",
    "\n",
    "**Master metrics collection, alerting, dashboards, and observability patterns for production systems**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Observability Overview - Monitoring, Logging, Alerting\n",
    "println(\"üìä MONITORING & OBSERVABILITY - PRODUCTION SYSTEMS INSIGHT\")\n",
    "println()\n",
    "\n",
    "println(\"üéØ The Three Pillars of Production Readiness:\")\n",
    "println(\"üîç Monitoring: Activity measurement and resource tracking\")\n",
    "println(\"üìã Logging: Detailed activity records with context\")\n",
    "println(\"üö® Alerting: Proactive incident detection and response\")\n",
    "println(\"üìä Dashboards: Visual insights into system behavior\")\n",
    "println()\n",
    "\n",
    "println(\"üèÜ Quality Attributes for Production Monitoring:\")\n",
    "println(\"‚úì Observability: Understanding system state from outputs\")\n",
    "println(\"‚úì Reliability: Fault tolerance and recovery metrics\")\n",
    "println(\"‚úì Performance: Throughput, latency, resource utilization\")\n",
    "println(\"‚úì Availability: Uptime, service level objectives (SLOs)\")\n",
    "println(\"‚úì Incident Response: Mean time to detection/recovery (MTTD/MTTR)\")\n",
    "println()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Metrics Collection & Analysis\n",
    "\n",
    "**Comprehensive metrics gathering with proper classification and aggregation patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Enterprise Metrics System with Scala\n",
    "sealed trait MetricType\n",
    "case object Counter extends MetricType        // Monotonically increasing values\n",
    "case object Gauge extends MetricType         // Instantaneous measurements\n",
    "case object Histogram extends MetricType     // Distributions (percentiles)\n",
    "case object Summary extends MetricType       // Stats with quantiles\n",
    "\n",
    "case class ServiceMetrics(\n",
    "  requestCount: Long = 0,\n",
    "  errorCount: Long = 0,\n",
    "  activeConnections: Int = 0,\n",
    "  responseTimeMs: List[Long] = Nil,\n",
    "  lastError: Option[String] = None,\n",
    "  uptimeSeconds: Long = 0\n",
    ")\n",
    "\n",
    "class MetricsCollector[F[_]: Concurrent: Timer](\n",
    "  serviceName: String,\n",
    "  backend: MetricsBackend[F]\n",
    ") {\n",
    "  \n",
    "  def recordRequest(service: String, responseTime: FiniteDuration): F[Unit] = {\n",
    "    for {\n",
    "      _ <- backend.incrementCounter(s\"$service.requests_total\")\n",
    "      _ <- backend.recordHistogram(s\"$service.request_duration_seconds\",\n",
    "          Map(\"service\" -> service, \"method\" -> \"GET\"),\n",
    "          responseTime.toMillis.toDouble / 1000.0)\n",
    "      _ <- backend.setGauge(s\"$service.last_request_timestamp\",\n",
    "          Map(\"service\" -> service), System.currentTimeMillis())\n",
    "    } yield ()\n",
    "  }\n",
    "  \n",
    "  def recordError(service: String, errorType: String): F[Unit] = {\n",
    "    backend.incrementCounter(s\"$service.errors_total\",\n",
    "      Map(\"service\" -> service, \"error_type\" -> errorType))\n",
    "  }\n",
    "  \n",
    "  def recordCircuitBreakerState(service: String, state: String): F[Unit] = {\n",
    "    backend.setGauge(s\"$service.circuit_breaker_state\",\n",
    "      Map(\"service\" -> service, \"state\" -> state), state match {\n",
    "        case \"closed\" => 0\n",
    "        case \"open\" => 1\n",
    "        case \"half_open\" => 2\n",
    "        case _ => -1\n",
    "      })\n",
    "  }\n",
    "\n",
    "  // Health check endpoint\n",
    "  def healthStatus(): F[HealthStatus] = {\n",
    "    for {\n",
    "      metrics <- backend.getServiceMetrics(serviceName)\n",
    "      totalRequests = metrics.getOrElse(\"requests_total\", 0.0).toLong\n",
    "      totalErrors = metrics.getOrElse(\"errors_total\", 0.0).toLong\n",
    "      errorRate = if (totalRequests > 0) (totalErrors.toDouble / totalRequests) else 0.0\n",
    "    } yield if (errorRate < 0.05) Healthy else Degraded\n",
    "  }\n",
    "}\n",
    "\n",
    "println(\"üìà Enterprise Metrics System Implemented\")\n",
    "println(\"‚Ä¢ Counter metrics for events (requests, errors)\")\n",
    "println(\"‚Ä¢ Histogram metrics for distributions (latencies)\")\n",
    "println(\"‚Ä¢ Gauge metrics for current values (connections, state)\")\n",
    "println(\"‚Ä¢ Health check integration with SLO tracking\")\n",
    "println(\"‚Ä¢ Service-level tagging for multi-tenant metrics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Structured Logging Patterns\n",
    "\n",
    "**Log management, correlation IDs, and observability-driven logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Enterprise Logging System\n",
    "sealed trait LogLevel\n",
    "case object DEBUG extends LogLevel\n",
    "case object INFO extends LogLevel\n",
    "case object WARN extends LogLevel\n",
    "case object ERROR extends LogLevel\n",
    "\n",
    "case class LogEntry(\n",
    "  timestamp: java.time.Instant,\n",
    "  level: LogLevel,\n",
    "  message: String,\n",
    "  correlationId: Option[String] = None,\n",
    "  userId: Option[String] = None,\n",
    "  requestId: Option[String] = None,\n",
    "  service: String,\n",
    "  context: Map[String, String] = Map.empty,\n",
    "  error: Option[Throwable] = None\n",
    ")\n",
    "\n",
    "class StructuredLogger[F[_]: Sync](\n",
    "  serviceName: String,\n",
    "  correlationIdGenerator: F[String]\n",
    ") {\n",
    "  \n",
    "  private val levels = Map(\n",
    "    DEBUG -> 10,\n",
    "    INFO -> 20,\n",
    "    WARN -> 30,\n",
    "    ERROR -> 40\n",
    "  )\n",
    "  \n",
    "  def info(msg: String, ctx: Map[String, String] = Map.empty): F[Unit] =\n",
    "    log(INFO, msg, ctx)\n",
    "    \n",
    "  def error(msg: String, error: Throwable, ctx: Map[String, String] = Map.empty): F[Unit] =\n",
    "    log(ERROR, msg, ctx, Some(error))\n",
    "    \n",
    "  def warn(msg: String, ctx: Map[String, String] = Map.empty): F[Unit] =\n",
    "    log(WARN, msg, ctx)\n",
    "    \n",
    "  def debug(msg: String, ctx: Map[String, String] = Map.empty): F[Unit] =\n",
    "    log(DEBUG, msg, ctx)\n",
    "\n",
    "  private def log(\n",
    "    level: LogLevel,\n",
    "    message: String,\n",
    "    context: Map[String, String],\n",
    "    error: Option[Throwable] = None\n",
    "  ): F[Unit] = {\n",
    "    for {\n",
    "      correlationId <- correlationIdGenerator\n",
    "      entry = LogEntry(\n",
    "        timestamp = java.time.Instant.now(),\n",
    "        level = level,\n",
    "        message = message,\n",
    "        correlationId = Some(correlationId),\n",
    "        service = serviceName,\n",
    "        context = context,\n",
    "        error = error\n",
    "      )\n",
    "      _ <- writeLogEntry(entry)\n",
    "      _ <- conditionallyAlert(entry) // Alert on critical events\n",
    "    } yield ()\n",
    "  }\n",
    "  \n",
    "  private def writeLogEntry(entry: LogEntry): F[Unit] = {\n",
    "    JsonLogger.toJson(entry).flatMap { json =>\n",
    "      println(s\"[${entry.level}] ${entry.service}: ${json}\")\n",
    "    }.handleErrorWith(_ => Sync[F].unit) // Logging errors don't crash the service\n",
    "  }\n",
    "  \n",
    "  private def conditionallyAlert(entry: LogEntry): F[Unit] = {\n",
    "    val shouldAlert = entry.level == ERROR && \n",
    "      entry.error.exists(_.isInstanceOf[CriticalBusinessError])\n",
    "    \n",
    "    if (shouldAlert) {\n",
    "      sendAlert(entry)\n",
    "    } else {\n",
    "      Sync[F].unit\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "case class CriticalBusinessError(msg: String) extends Exception(msg)\n",
    "\n",
    "println(\"üìã Structured Logging System Implemented\")\n",
    "println(\"‚Ä¢ Correlation IDs for request tracing\")\n",
    "println(\"‚Ä¢ Structured JSON logging for analysis\")\n",
    "println(\"‚Ä¢ Log levels with severity hierarchy\")\n",
    "println(\"‚Ä¢ Error telemetry and alerting integration\")\n",
    "println(\"‚Ä¢ Non-blocking logging that never crashes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîî Alerting & Incident Management\n",
    "\n",
    "**Smart alerting systems with escalations, de-duplication, and automated incident response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Production Alerting System\n",
    "sealed trait AlertSeverity\n",
    "case object Info extends AlertSeverity\n",
    "case object Warning extends AlertSeverity\n",
    "case object Critical extends AlertSeverity\n",
    "case object Pager extends AlertSeverity\n",
    "\n",
    "case class Alert(\n",
    "  id: String,\n",
    "  severity: AlertSeverity,\n",
    "  service: String,\n",
    "  title: String,\n",
    "  description: String,\n",
    "  timestamp: java.time.Instant,\n",
    "  tags: Set[String] = Set.empty,\n",
    "  resolved: Boolean = false\n",
    ")\n",
    "\n",
    "class AlertManager[F[_]: Concurrent: Timer](\n",
    "  thresholds: AlertThresholds,\n",
    "  notificationService: NotificationService[F],\n",
    "  alertStore: AlertStore[F]\n",
    ") {\n",
    "  \n",
    "  private val activeAlerts = Ref.of[F, Map[String, Alert]](Map.empty)\n",
    "  \n",
    "  // SLO-based alert rules\n",
    "  def checkSLOMetrics(metrics: ServiceMetrics): F[Unit] = {\n",
    "    val errorRate = if (metrics.requestCount > 0) {\n",
    "      metrics.errorCount.toDouble / metrics.requestCount\n",
    "    } else 0.0\n",
    "    \n",
    "    for {\n",
    "      _ <- if (errorRate > thresholds.errorRatePercent / 100.0) {\n",
    "        fireAlert(\n",
    "          s\"${metrics.serviceName} error rate: ${errorRate * 100}%.1f%%\",\n",
    "          s\"Error rate exceeded ${thresholds.errorRatePercent}% threshold\",\n",
    "          if (errorRate > thresholds.errorRatePercent * 2 / 100.0) Pager else Critical\n",
    "        )\n",
    "      } else clearAlert(\"high_error_rate\")\n",
    "      \n",
    "      _ <- if (metrics.responseTimeP95 > thresholds.p95LatencyMs) {\n",
    "        fireAlert(\n",
    "          s\"${metrics.serviceName} P95 latency: ${metrics.responseTimeP95}ms\",\n",
    "          s\"95th percentile latency exceeded ${thresholds.p95LatencyMs}ms threshold\",\n",
    "          Warning\n",
    "        )\n",
    "      } else clearAlert(\"high_latency\")\n",
    "      \n",
    "    } yield ()\n",
    "  }\n",
    "  \n",
    "  private def fireAlert(title: String, description: String, severity: AlertSeverity): F[Unit] = {\n",
    "    val alertId = generateAlertId(title)\n",
    "    \n",
    "    for {\n",
    "      alreadyActive <- activeAlerts.get.map(_.contains(alertId))\n",
    "      _ <- if (!alreadyActive) {\n",
    "        for {\n",
    "          alert <- createAlert(alertId, title, description, severity)\n",
    "          _ <- alertStore.save(alert)\n",
    "          _ <- activeAlerts.update(_ + (alert.id -> alert))\n",
    "          _ <- notificationService.notify(alert)\n",
    "          _ <- if (severity == Pager) escalationManager.scheduleEscalation(alert)\n",
    "        } yield ()\n",
    "      } else Sync[F].unit\n",
    "    } yield ()\n",
    "  }\n",
    "  \n",
    "  def resolveAlert(alertId: String): F[Unit] = {\n",
    "    for {\n",
    "      alert <- activeAlerts.get.map(_.get(alertId))\n",
    "      _ <- alert.map(a => \n",
    "        alertStore.update(a.copy(resolved = true)) *>\n",
    "        activeAlerts.update(_ - alertId)\n",
    "      ).getOrElse(Sync[F].unit)\n",
    "    } yield ()\n",
    "  }\n",
    "  \n",
    "  private def createAlert(id: String, title: String, desc: String, sev: AlertSeverity): F[Alert] = {\n",
    "    Sync[F].pure(Alert(\n",
    "      id = id,\n",
    "      severity = sev,\n",
    "      service = \"system\",\n",
    "      title = title,\n",
    "      description = desc,\n",
    "      timestamp = java.time.Instant.now(),\n",
    "      tags = Set(\"auto-generated\", \"monitoring\")\n",
    "    ))\n",
    "  }\n",
    "\n",
    "  def getActiveAlerts(): F[List[Alert]] = \n",
    "    activeAlerts.get.map(_.values.toList.filter(!_.resolved))\n",
    "}\n",
    "\n",
    "println(\"üîî Enterprise Alerting System Implemented\")\n",
    "println(\"‚Ä¢ SLO-based automated alerts\")\n",
    "println(\"‚Ä¢ Severity levels with escalation paths\")\n",
    "println(\"‚Ä¢ Alert de-duplication and noise reduction\")\n",
    "println(\"‚Ä¢ Incident tracking with resolution workflow\")\n",
    "println(\"‚Ä¢ Pagerduty integration for critical alerts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Dashboard & Visualization Patterns\n",
    "\n",
    "**Creating production dashboards for system insights and business intelligence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Dashboard Configuration and Analytics\n",
    "println(\"üìä PRODUCTION DASHBOARDS - SYSTEM VISUALIZATION\")\n",
    "println()\n",
    "\n",
    "println(\"üî• Essential Dashboard Components:\")\n",
    "println()\n",
    "\n",
    "println(\"1. üîÑ Service Health Overview\")\n",
    "println(\"   ‚úì Current status of all services\")\n",
    "println(\"   ‚úì Uptime and availability percentage\")\n",
    "println(\"   ‚úì Active alerts and critical issues\")\n",
    "println(\"   ‚úì Circuit breaker states\")\n",
    "println()\n",
    "\n",
    "println(\"2. üìà Performance Metrics Dashboard\")\n",
    "println(\"   ‚úì Request rate (RPS, RPM)\")\n",
    "println(\"   ‚úì Response time percentiles (P50, P95, P99)\")\n",
    "println(\"   ‚úì Error rates and success rates\")\n",
    "println(\"   ‚úì Throughput and resource utilization\")\n",
    "println()\n",
    "\n",
    "println(\"3. üéØ Business Metrics Integration\")\n",
    "println(\"   ‚úì User engagement metrics\")\n",
    "println(\"   ‚úì Revenue and transaction KPIs\")\n",
    "println(\"   ‚úì Feature adoption rates\")\n",
    "println(\"   ‚úì Customer satisfaction scores\")\n",
    "println()\n",
    "\n",
    "println(\"4. üîç Detailed Investigation Panels\")\n",
    "println(\"   ‚úì Log correlation and trace views\")\n",
    "println(\"   ‚úì Database query performance\")\n",
    "println(\"   ‚úì Cache hit rates and miss penalties\")\n",
    "println(\"   ‚úì End-to-end request flow visualization\")\n",
    "println()\n",
    "\n",
    "println(\"üõ†Ô∏è Dashboard Tools Integration:\")\n",
    "println(\"‚Ä¢ Grafana: Real-time metrics dashboarding\")\n",
    "println(\"‚Ä¢ Kibana: Log aggregation and search\")\n",
    "println(\"‚Ä¢ Jaeger/Zipkin: Distributed tracing\")\n",
    "println(\"‚Ä¢ Prometheus: Metrics collection and querying\")\n",
    "\n",
    "println(\"\\nüìä MONITORING MATURITY LEVELS:\")\n",
    "println(\"Level 1: Manual monitoring (alerting on obvious issues)\")\n",
    "println(\"Level 2: Automated alerting (SLO-based, intelligent thresholds)\")\n",
    "println(\"Level 3: Predictive analytics (anomaly detection, forecasting)\")\n",
    "println(\"Level 4: Self-healing systems (auto-remediation, chaos engineering)\")\n",
    "\n",
    "println(\"\\nDon't forget: Observing a system changes its behavior!\")\n",
    "println(\"Monitoring should add <5% overhead and never impact user experience.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
